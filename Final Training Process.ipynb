{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d909e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f3b772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e9b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path='processed11_data.xlsx'\n",
    "data=pd.read_excel(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c51d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>joined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi jarvis</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'jarvis']</td>\n",
       "      <td>['hi', 'jarvi']</td>\n",
       "      <td>['hi', 'jarvis']</td>\n",
       "      <td>['hi', 'jarvis']</td>\n",
       "      <td>hijarvis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello goodmorning</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'goodmorning']</td>\n",
       "      <td>['hello', 'goodmorn']</td>\n",
       "      <td>['hello', 'goodmorning']</td>\n",
       "      <td>['hello', 'goodmorning']</td>\n",
       "      <td>hellogoodmorning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello jarvis how are you?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'jarvis', 'how', 'are', 'you', '?']</td>\n",
       "      <td>['hello', 'jarvi', 'how', 'are', 'you', '?']</td>\n",
       "      <td>['hello', 'jarvis', 'how', 'are', 'you?']</td>\n",
       "      <td>['hello', 'jarvis', 'how', 'are', 'you']</td>\n",
       "      <td>hellojarvishowareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good morning</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'morning']</td>\n",
       "      <td>['good', 'morn']</td>\n",
       "      <td>['good', 'morning']</td>\n",
       "      <td>['good', 'morning']</td>\n",
       "      <td>goodmorning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good afternoon</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>goodafternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how are you?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['how', 'are', 'you', '?']</td>\n",
       "      <td>['how', 'are', 'you', '?']</td>\n",
       "      <td>['how', 'are', 'you?']</td>\n",
       "      <td>['how', 'are', 'you']</td>\n",
       "      <td>howareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hello</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what's up?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['what', \"'s\", 'up', '?']</td>\n",
       "      <td>['what', \"'s\", 'up', '?']</td>\n",
       "      <td>[\"what's\", 'up?']</td>\n",
       "      <td>['whats', 'up']</td>\n",
       "      <td>whatsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hello good evening</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'good', 'evening']</td>\n",
       "      <td>['hello', 'good', 'even']</td>\n",
       "      <td>['hello', 'good', 'evening']</td>\n",
       "      <td>['hello', 'good', 'evening']</td>\n",
       "      <td>hellogoodevening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hi goodmorning</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'goodmorning']</td>\n",
       "      <td>['hi', 'goodmorn']</td>\n",
       "      <td>['hi', 'goodmorning']</td>\n",
       "      <td>['hi', 'goodmorning']</td>\n",
       "      <td>higoodmorning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hi goodevening</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'goodevening']</td>\n",
       "      <td>['hi', 'goodeven']</td>\n",
       "      <td>['hi', 'goodevening']</td>\n",
       "      <td>['hi', 'goodevening']</td>\n",
       "      <td>higoodevening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hi what's up?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'what', \"'s\", 'up', '?']</td>\n",
       "      <td>['hi', 'what', \"'s\", 'up', '?']</td>\n",
       "      <td>['hi', \"what's\", 'up?']</td>\n",
       "      <td>['hi', 'whats', 'up']</td>\n",
       "      <td>hiwhatsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hi how  are you</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>hihowareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how's the weather</td>\n",
       "      <td>weather</td>\n",
       "      <td>['how', \"'s\", 'the', 'weather']</td>\n",
       "      <td>['how', \"'s\", 'the', 'weather']</td>\n",
       "      <td>[\"how's\", 'the', 'weather']</td>\n",
       "      <td>['hows', 'the', 'weather']</td>\n",
       "      <td>howstheweather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>what's the weather like</td>\n",
       "      <td>weather</td>\n",
       "      <td>['what', \"'s\", 'the', 'weather', 'like']</td>\n",
       "      <td>['what', \"'s\", 'the', 'weather', 'like']</td>\n",
       "      <td>[\"what's\", 'the', 'weather', 'like']</td>\n",
       "      <td>['whats', 'the', 'weather', 'like']</td>\n",
       "      <td>whatstheweatherlike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what's the temperature</td>\n",
       "      <td>weather_temperature</td>\n",
       "      <td>['what', \"'s\", 'the', 'temperature']</td>\n",
       "      <td>['what', \"'s\", 'the', 'temperatur']</td>\n",
       "      <td>[\"what's\", 'the', 'temperature']</td>\n",
       "      <td>['whats', 'the', 'temperature']</td>\n",
       "      <td>whatsthetemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>temperature</td>\n",
       "      <td>weather_temperature</td>\n",
       "      <td>['temperature']</td>\n",
       "      <td>['temperatur']</td>\n",
       "      <td>['temperature']</td>\n",
       "      <td>['temperature']</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>humidity</td>\n",
       "      <td>weather_humidity</td>\n",
       "      <td>['humidity']</td>\n",
       "      <td>['humid']</td>\n",
       "      <td>['humidity']</td>\n",
       "      <td>['humidity']</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>what is the humidity</td>\n",
       "      <td>weather_humdity</td>\n",
       "      <td>['what', 'is', 'the', 'humidity']</td>\n",
       "      <td>['what', 'is', 'the', 'humid']</td>\n",
       "      <td>['what', 'is', 'the', 'humidity']</td>\n",
       "      <td>['what', 'is', 'the', 'humidity']</td>\n",
       "      <td>whatisthehumidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>how hot is it in mumbai?</td>\n",
       "      <td>weather_condition</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai?']</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai']</td>\n",
       "      <td>howhotisitinmumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text               intent  \\\n",
       "0                   hi jarvis             greeting   \n",
       "1           hello goodmorning             greeting   \n",
       "2   hello jarvis how are you?             greeting   \n",
       "3                good morning             greeting   \n",
       "4              good afternoon             greeting   \n",
       "5                how are you?             greeting   \n",
       "6                       hello             greeting   \n",
       "7                  what's up?             greeting   \n",
       "8          hello good evening             greeting   \n",
       "9              hi goodmorning             greeting   \n",
       "10             hi goodevening             greeting   \n",
       "11              hi what's up?             greeting   \n",
       "12            hi how  are you             greeting   \n",
       "13          how's the weather              weather   \n",
       "14    what's the weather like              weather   \n",
       "15     what's the temperature  weather_temperature   \n",
       "16                temperature  weather_temperature   \n",
       "17                   humidity     weather_humidity   \n",
       "18       what is the humidity      weather_humdity   \n",
       "19   how hot is it in mumbai?    weather_condition   \n",
       "\n",
       "                                     tokenized_text  \\\n",
       "0                                  ['hi', 'jarvis']   \n",
       "1                          ['hello', 'goodmorning']   \n",
       "2     ['hello', 'jarvis', 'how', 'are', 'you', '?']   \n",
       "3                               ['good', 'morning']   \n",
       "4                             ['good', 'afternoon']   \n",
       "5                        ['how', 'are', 'you', '?']   \n",
       "6                                         ['hello']   \n",
       "7                         ['what', \"'s\", 'up', '?']   \n",
       "8                      ['hello', 'good', 'evening']   \n",
       "9                             ['hi', 'goodmorning']   \n",
       "10                            ['hi', 'goodevening']   \n",
       "11                  ['hi', 'what', \"'s\", 'up', '?']   \n",
       "12                      ['hi', 'how', 'are', 'you']   \n",
       "13                  ['how', \"'s\", 'the', 'weather']   \n",
       "14         ['what', \"'s\", 'the', 'weather', 'like']   \n",
       "15             ['what', \"'s\", 'the', 'temperature']   \n",
       "16                                  ['temperature']   \n",
       "17                                     ['humidity']   \n",
       "18                ['what', 'is', 'the', 'humidity']   \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']   \n",
       "\n",
       "                                       stemmed_text  \\\n",
       "0                                   ['hi', 'jarvi']   \n",
       "1                             ['hello', 'goodmorn']   \n",
       "2      ['hello', 'jarvi', 'how', 'are', 'you', '?']   \n",
       "3                                  ['good', 'morn']   \n",
       "4                             ['good', 'afternoon']   \n",
       "5                        ['how', 'are', 'you', '?']   \n",
       "6                                         ['hello']   \n",
       "7                         ['what', \"'s\", 'up', '?']   \n",
       "8                         ['hello', 'good', 'even']   \n",
       "9                                ['hi', 'goodmorn']   \n",
       "10                               ['hi', 'goodeven']   \n",
       "11                  ['hi', 'what', \"'s\", 'up', '?']   \n",
       "12                      ['hi', 'how', 'are', 'you']   \n",
       "13                  ['how', \"'s\", 'the', 'weather']   \n",
       "14         ['what', \"'s\", 'the', 'weather', 'like']   \n",
       "15              ['what', \"'s\", 'the', 'temperatur']   \n",
       "16                                   ['temperatur']   \n",
       "17                                        ['humid']   \n",
       "18                   ['what', 'is', 'the', 'humid']   \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']   \n",
       "\n",
       "                                lemmatized_text  \\\n",
       "0                              ['hi', 'jarvis']   \n",
       "1                      ['hello', 'goodmorning']   \n",
       "2     ['hello', 'jarvis', 'how', 'are', 'you?']   \n",
       "3                           ['good', 'morning']   \n",
       "4                         ['good', 'afternoon']   \n",
       "5                        ['how', 'are', 'you?']   \n",
       "6                                     ['hello']   \n",
       "7                             [\"what's\", 'up?']   \n",
       "8                  ['hello', 'good', 'evening']   \n",
       "9                         ['hi', 'goodmorning']   \n",
       "10                        ['hi', 'goodevening']   \n",
       "11                      ['hi', \"what's\", 'up?']   \n",
       "12                  ['hi', 'how', 'are', 'you']   \n",
       "13                  [\"how's\", 'the', 'weather']   \n",
       "14         [\"what's\", 'the', 'weather', 'like']   \n",
       "15             [\"what's\", 'the', 'temperature']   \n",
       "16                              ['temperature']   \n",
       "17                                 ['humidity']   \n",
       "18            ['what', 'is', 'the', 'humidity']   \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai?']   \n",
       "\n",
       "                                  cleaned_text           joined_text  \n",
       "0                             ['hi', 'jarvis']              hijarvis  \n",
       "1                     ['hello', 'goodmorning']      hellogoodmorning  \n",
       "2     ['hello', 'jarvis', 'how', 'are', 'you']  hellojarvishowareyou  \n",
       "3                          ['good', 'morning']           goodmorning  \n",
       "4                        ['good', 'afternoon']         goodafternoon  \n",
       "5                        ['how', 'are', 'you']             howareyou  \n",
       "6                                    ['hello']                 hello  \n",
       "7                              ['whats', 'up']               whatsup  \n",
       "8                 ['hello', 'good', 'evening']      hellogoodevening  \n",
       "9                        ['hi', 'goodmorning']         higoodmorning  \n",
       "10                       ['hi', 'goodevening']         higoodevening  \n",
       "11                       ['hi', 'whats', 'up']             hiwhatsup  \n",
       "12                 ['hi', 'how', 'are', 'you']           hihowareyou  \n",
       "13                  ['hows', 'the', 'weather']        howstheweather  \n",
       "14         ['whats', 'the', 'weather', 'like']   whatstheweatherlike  \n",
       "15             ['whats', 'the', 'temperature']   whatsthetemperature  \n",
       "16                             ['temperature']           temperature  \n",
       "17                                ['humidity']              humidity  \n",
       "18           ['what', 'is', 'the', 'humidity']     whatisthehumidity  \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai']    howhotisitinmumbai  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85de936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Packages for Classification in Navie-Bayes\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer        #Used For Converting text into Numerical(Binary Data)\n",
    "from sklearn.model_selection import train_test_split               #Used for splitting dataset for Training and testing the performance\n",
    "from sklearn.naive_bayes     import MultinomialNB                  #Used for text based Classification & identify the intent\n",
    "from sklearn.metrics   import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c78634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'jarvi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'goodmorn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'jarvi', 'how', 'are', 'you', '?']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'morn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>joke</td>\n",
       "      <td>['readi', 'for', 'laugh', 'tell', 'me', 'joke']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>joke</td>\n",
       "      <td>['need', 'a', 'break', 'entertain', 'me', 'wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>joke</td>\n",
       "      <td>['what', 'your', 'favorit', 'joke', '?']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>joke</td>\n",
       "      <td>['tell', 'me', 'joke', 'that', 'make', 'everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>joke</td>\n",
       "      <td>['joke', 'make', 'ani', 'day', 'better', 'tell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       intent                                       stemmed_text\n",
       "0    greeting                                    ['hi', 'jarvi']\n",
       "1    greeting                              ['hello', 'goodmorn']\n",
       "2    greeting       ['hello', 'jarvi', 'how', 'are', 'you', '?']\n",
       "3    greeting                                   ['good', 'morn']\n",
       "4    greeting                              ['good', 'afternoon']\n",
       "..        ...                                                ...\n",
       "144      joke    ['readi', 'for', 'laugh', 'tell', 'me', 'joke']\n",
       "145      joke  ['need', 'a', 'break', 'entertain', 'me', 'wit...\n",
       "146      joke           ['what', 'your', 'favorit', 'joke', '?']\n",
       "147      joke  ['tell', 'me', 'joke', 'that', 'make', 'everyo...\n",
       "148      joke  ['joke', 'make', 'ani', 'day', 'better', 'tell...\n",
       "\n",
       "[149 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a DataFrame\n",
    "df=pd.DataFrame(data)\n",
    "df[['intent','stemmed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b08842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         greeting       1.00      1.00      1.00         2\n",
      "             joke       1.00      1.00      1.00         4\n",
      "          leaving       0.50      1.00      0.67         1\n",
      "         leaving        0.00      0.00      0.00         1\n",
      "             news       1.00      1.00      1.00         1\n",
      "      open_google       0.00      0.00      0.00         1\n",
      "     open_youtube       0.00      0.00      0.00         1\n",
      "    search google       0.00      0.00      0.00         1\n",
      "   search_google        0.00      0.00      0.00         0\n",
      "   search_youtube       0.80      1.00      0.89         4\n",
      "            timer       1.00      1.00      1.00         5\n",
      "          weather       0.70      1.00      0.82         7\n",
      "weather_condition       0.00      0.00      0.00         1\n",
      "  weather_humdity       0.00      0.00      0.00         1\n",
      "\n",
      "         accuracy                           0.80        30\n",
      "        macro avg       0.43      0.50      0.46        30\n",
      "     weighted avg       0.69      0.80      0.73        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Spliting the data into training & Testing Sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['stemmed_text'],df['intent'],test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using CountVectorizer (you can also use TfidfVectorizer)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create and train the Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d303c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using CountVectorizer (you can also use TfidfVectorizer)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)       #Convert X_train into Numerical by fiting & transform\n",
    "X_test_vectorized = vectorizer.transform(X_test)             #Convert X_test into Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7dbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "#Training the X_train(numerical) &  y_train(intent) data with MultiNomial\n",
    "nb_classifier.fit(X_train_vectorized, y_train)                        \n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test_vectorized)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066688ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Classifier\n",
    "accuracy= accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909bbcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d7f6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query:open youtube and search virat kholi\n",
      "Predicted Intent: search_youtube\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import re\n",
    "\n",
    "# Assuming df, vectorizer, and nb_classifier are already defined from your training code\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # You can add any text preprocessing steps here, like removing special characters or stemming\n",
    "    # For example, removing non-alphanumeric characters and converting to lowercase:\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Create a pipeline with vectorizer and classifier\n",
    "model_pipeline = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Assuming df, vectorizer, and nb_classifier are already defined from your training code\n",
    "X = df['cleaned_text']\n",
    "y = df['intent']\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "model_pipeline.fit(X, y)\n",
    "\n",
    "# Function to predict intent\n",
    "def predict_intent(input_text):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess_text(input_text)\n",
    "    \n",
    "    # Use the trained pipeline to predict intent\n",
    "    predicted_intent = model_pipeline.predict([preprocessed_text])[0]\n",
    "    \n",
    "    return predicted_intent\n",
    "\n",
    "# Example usage\n",
    "input_text=input('Enter your query:')\n",
    "predicted_intent = predict_intent(input_text)\n",
    "print(f\"Predicted Intent: {predicted_intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df0700f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier\u001b[39;00m\n\u001b[0;32m      2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m----> 3\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred)\n\u001b[0;32m      4\u001b[0m report\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8511dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: {'compliment': 0.0, 'date_time': 0.57, 'greeting': 0.44, 'insult': 0.0, 'joke': 0.0, 'leaving': 1.0, 'location': 1.0, 'open_in_browser': 1.0, 'personal_q': 0.0, 'repeat': 1.0, 'timer': 0.5, 'weather': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have your classification report as a string\n",
    "classification_report_str = \"\"\"\n",
    "                 precision    recall  f1-score   support\n",
    "     compliment       0.00      0.00      0.00         2\n",
    "      date_time       0.57      1.00      0.73         4\n",
    "      greeting       0.44      0.80      0.57         5\n",
    "      insult       0.00      0.00      0.00         2\n",
    "      joke       0.00      0.00      0.00         1\n",
    "      leaving       1.00      0.67      0.80         3\n",
    "      location       1.00      0.25      0.40         4\n",
    "      open_in_browser       1.00      1.00      1.00         5\n",
    "      personal_q       0.00      0.00      0.00         0\n",
    "      repeat       1.00      1.00      1.00         3\n",
    "      timer       0.50      1.00      0.67         1\n",
    "      weather       1.00      1.00      1.00         3\n",
    "\n",
    "       accuracy                           0.70        33\n",
    "      macro avg       0.54      0.56      0.51        33\n",
    "   weighted avg       0.70      0.70      0.65        33\n",
    "\"\"\"\n",
    "\n",
    "# Split the classification report into lines\n",
    "lines = classification_report_str.split('\\n')\n",
    "\n",
    "# Create dictionaries to store precision, recall, and f1-score\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1_score = {}\n",
    "\n",
    "# Iterate through the lines and extract values\n",
    "for line in lines[2:-5]:\n",
    "    cols = line.split()\n",
    "    class_name = cols[0]\n",
    "    precision[class_name] = float(cols[1])\n",
    "    recall[class_name] = float(cols[2])\n",
    "    f1_score[class_name] = float(cols[3])\n",
    "\n",
    "# Print or use the dictionaries as needed\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a935e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: {'compliment': 0.0, 'date_time': 1.0, 'greeting': 0.8, 'insult': 0.0, 'joke': 0.0, 'leaving': 0.67, 'location': 0.25, 'open_in_browser': 1.0, 'personal_q': 0.0, 'repeat': 1.0, 'timer': 1.0, 'weather': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e4abb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: {'compliment': 0.0, 'date_time': 0.73, 'greeting': 0.57, 'insult': 0.0, 'joke': 0.0, 'leaving': 0.8, 'location': 0.4, 'open_in_browser': 1.0, 'personal_q': 0.0, 'repeat': 1.0, 'timer': 0.67, 'weather': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c9d0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90a78ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have your classification report as a string\n",
    "classification_report_str = \"\"\"\n",
    "                 precision    recall  f1-score   support\n",
    "     compliment       0.00      0.00      0.00         2\n",
    "      date_time       0.57      1.00      0.73         4\n",
    "      greeting       0.44      0.80      0.57         5\n",
    "      insult       0.00      0.00      0.00         2\n",
    "      joke       0.00      0.00      0.00         1\n",
    "      leaving       1.00      0.67      0.80         3\n",
    "      location       1.00      0.25      0.40         4\n",
    "      open_in_browser       1.00      1.00      1.00         5\n",
    "      personal_q       0.00      0.00      0.00         0\n",
    "      repeat       1.00      1.00      1.00         3\n",
    "      timer       0.50      1.00      0.67         1\n",
    "      weather       1.00      1.00      1.00         3\n",
    "\n",
    "       accuracy                           0.70        33\n",
    "      macro avg       0.54      0.56      0.51        33\n",
    "   weighted avg       0.70      0.70      0.65        33\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88df3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=classification_report_str.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5869265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header=[col.strip() for col in lines[0].split()]\n",
    "# header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaebb4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision={}\n",
    "recall={}\n",
    "f1_score={}\n",
    "support={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61d0d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through the lines and extract value\n",
    "for line in lines[2:-5]:\n",
    "    cols=line.split()\n",
    "    class_name=cols[0]\n",
    "    precision[class_name]=float(cols[1])\n",
    "    recall[class_name]=float(cols[2])\n",
    "    f1_score[class_name]=float(cols[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0c462b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision {'compliment': 0.0, 'date_time': 0.57, 'greeting': 0.44, 'insult': 0.0, 'joke': 0.0, 'leaving': 1.0, 'location': 1.0, 'open_in_browser': 1.0, 'personal_q': 0.0, 'repeat': 1.0, 'timer': 0.5, 'weather': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"precision\",precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "946b2c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = {'compliment': 0.0, 'date_time': 0.73, 'greeting': 0.57, 'insult': 0.0, 'joke': 0.0, 'leaving': 0.8, 'location': 0.4, 'open_in_browser': 1.0, 'personal_q': 0.0, 'repeat': 1.0, 'timer': 0.67, 'weather': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score =\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf72d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall {'compliment': 0.0, 'date_time': 1.0, 'greeting': 0.8, 'insult': 0.0, 'joke': 0.0, 'leaving': 0.67, 'location': 0.25, 'open_in_browser': 1.0, 'personal_q': 0.0, 'repeat': 1.0, 'timer': 1.0, 'weather': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"recall\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    \"class\":['compliment',\"date_time\",\"greeting\",\"insult\",\"joke\",\"leaving\",\"location\",\"open_in_browser\",\"personal_q\",\"repeat\",'timer',\"weather\"],\n",
    "    'Precision':[0.00, 0.57, 0.44, 0.00, 0.00, 1.00, 1.00, 1.00, 0.00, 1.00, 0.50, 1.00],\n",
    "    \"f1_score\":[0.00, 0.73, 0.57, 0.00, 0.00, 0.80, 0.40, 1.00, 0.00, 1.00, 0.67, 1.00],\n",
    "    \"support\":[2, 4, 5, 2, 1, 3, 4, 5, 0, 3, 1, 3],\n",
    "    \"recall\":[0.0,1.0,0.8,0.0,0.0,0.67,0.25,1.0,0.0,1.0,1.0,1.0]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0b4cc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compliment</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date_time</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greeting</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joke</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>leaving</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>location</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>open_in_browser</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>personal_q</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>repeat</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>timer</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>weather</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              class  Precision  f1_score  support  recall\n",
       "0        compliment       0.00      0.00        2    0.00\n",
       "1         date_time       0.57      0.73        4    1.00\n",
       "2          greeting       0.44      0.57        5    0.80\n",
       "3            insult       0.00      0.00        2    0.00\n",
       "4              joke       0.00      0.00        1    0.00\n",
       "5           leaving       1.00      0.80        3    0.67\n",
       "6          location       1.00      0.40        4    0.25\n",
       "7   open_in_browser       1.00      1.00        5    1.00\n",
       "8        personal_q       0.00      0.00        0    0.00\n",
       "9            repeat       1.00      1.00        3    1.00\n",
       "10            timer       0.50      0.67        1    1.00\n",
       "11          weather       1.00      1.00        3    1.00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['class',\"Precision\",'recall','f1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ff716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already trained your nb_classifier and vectorizer\n",
    "\n",
    "# Create a function to predict intent\n",
    "def predict_intent(text):\n",
    "    # Vectorize the input text using the same vectorizer used during training\n",
    "    text_vectorized = vectorizer.transform([text])\n",
    "    \n",
    "    # Predict the intent\n",
    "    intent = nb_classifier.predict(text_vectorized)[0]\n",
    "    return intent\n",
    "\n",
    "# Example usage\n",
    "while True:\n",
    "    user_input = input(\"Enter your text (or 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    intent = predict_intent(user_input)\n",
    "    print(f\"Predicted Intent: {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to Predict Intent\n",
    "def predict_intent(text):\n",
    "    text_vectorized=vectorizer.transform([text])\n",
    "    \n",
    "    #Predict the intent\n",
    "    intent=nb_classifier.predict(text_vectorized)[0]\n",
    "    return intent\n",
    "\n",
    "while True:\n",
    "    user_input=input(\"Enter your tex (of 'exit' to quit):\")\n",
    "    if user_input.lower()=='exit':\n",
    "        break\n",
    "    intent=predict_intent(user_input)\n",
    "    print(f\"Predicted Intent: {intent}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c72115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e635f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9c69bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintent\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Input features (intents)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponse\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Target variable (responses)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X = df['intent']  # Input features (intents)\n",
    "y = df['Response']  # Target variable (responses)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Example usage: Predict a response based on an intent\n",
    "new_intent = input(\"Enter intent\")  # Replace with the intent you want to predict\n",
    "new_intent_vectorized = vectorizer.transform([new_intent])\n",
    "predicted_response = rf_classifier.predict(new_intent_vectorized)[0]\n",
    "print(f\"Predicted response for intent '{new_intent}': {predicted_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fd789a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training & testing sets\n",
    "vectorizer=TfidfVectorizer()\n",
    "X=df['intent']\n",
    "y=df['Response']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train_vectorized=vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e84dec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41b3630a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc08e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer\n",
      "TF-IDF value in document 0: 1.0\n",
      "greeting\n",
      "TF-IDF value in document 0: 0.0\n",
      "weather\n",
      "TF-IDF value in document 0: 0.0\n",
      "personal_q\n",
      "TF-IDF value in document 0: 0.0\n",
      "leaving\n",
      "TF-IDF value in document 0: 0.0\n",
      "date_time\n",
      "TF-IDF value in document 0: 0.0\n",
      "open_in_browser\n",
      "TF-IDF value in document 0: 0.0\n",
      "compliment\n",
      "TF-IDF value in document 0: 0.0\n",
      "repeat\n",
      "TF-IDF value in document 0: 0.0\n",
      "appreciation\n",
      "TF-IDF value in document 0: 0.0\n",
      "location\n",
      "TF-IDF value in document 0: 0.0\n",
      "joke\n",
      "TF-IDF value in document 0: 0.0\n",
      "insult\n",
      "TF-IDF value in document 0: 0.0\n",
      "presonal_q\n",
      "TF-IDF value in document 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train_vectorized is your TF-IDF vectorized data\n",
    "# and vectorizer is the TF-IDF vectorizer you used\n",
    "for feature_name, feature_index in vectorizer.vocabulary_.items():\n",
    "    # Access the feature name (word or phrase)\n",
    "    print(feature_name)\n",
    "    \n",
    "    # Access the TF-IDF value of this feature in a specific document\n",
    "    # For example, the TF-IDF value of 'feature_name' in the first document\n",
    "    tfidf_value = X_train_vectorized[0, feature_index]\n",
    "    print(f\"TF-IDF value in document 0: {tfidf_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00272f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
