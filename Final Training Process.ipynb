{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d909e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a425e55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3b772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\siddesh vichare\\downloads\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e9b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path='processed11_data.xlsx'\n",
    "data=pd.read_excel(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c51d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>joined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi jarvis</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'jarvis']</td>\n",
       "      <td>['hi', 'jarvi']</td>\n",
       "      <td>['hi', 'jarvis']</td>\n",
       "      <td>['hi', 'jarvis']</td>\n",
       "      <td>hijarvis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello goodmorning</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'goodmorning']</td>\n",
       "      <td>['hello', 'goodmorn']</td>\n",
       "      <td>['hello', 'goodmorning']</td>\n",
       "      <td>['hello', 'goodmorning']</td>\n",
       "      <td>hellogoodmorning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello jarvis how are you?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'jarvis', 'how', 'are', 'you', '?']</td>\n",
       "      <td>['hello', 'jarvi', 'how', 'are', 'you', '?']</td>\n",
       "      <td>['hello', 'jarvis', 'how', 'are', 'you?']</td>\n",
       "      <td>['hello', 'jarvis', 'how', 'are', 'you']</td>\n",
       "      <td>hellojarvishowareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good morning</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'morning']</td>\n",
       "      <td>['good', 'morn']</td>\n",
       "      <td>['good', 'morning']</td>\n",
       "      <td>['good', 'morning']</td>\n",
       "      <td>goodmorning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good afternoon</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "      <td>goodafternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how are you?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['how', 'are', 'you', '?']</td>\n",
       "      <td>['how', 'are', 'you', '?']</td>\n",
       "      <td>['how', 'are', 'you?']</td>\n",
       "      <td>['how', 'are', 'you']</td>\n",
       "      <td>howareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hello</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>['hello']</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what's up?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['what', \"'s\", 'up', '?']</td>\n",
       "      <td>['what', \"'s\", 'up', '?']</td>\n",
       "      <td>[\"what's\", 'up?']</td>\n",
       "      <td>['whats', 'up']</td>\n",
       "      <td>whatsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hello good evening</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'good', 'evening']</td>\n",
       "      <td>['hello', 'good', 'even']</td>\n",
       "      <td>['hello', 'good', 'evening']</td>\n",
       "      <td>['hello', 'good', 'evening']</td>\n",
       "      <td>hellogoodevening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hi goodmorning</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'goodmorning']</td>\n",
       "      <td>['hi', 'goodmorn']</td>\n",
       "      <td>['hi', 'goodmorning']</td>\n",
       "      <td>['hi', 'goodmorning']</td>\n",
       "      <td>higoodmorning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hi goodevening</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'goodevening']</td>\n",
       "      <td>['hi', 'goodeven']</td>\n",
       "      <td>['hi', 'goodevening']</td>\n",
       "      <td>['hi', 'goodevening']</td>\n",
       "      <td>higoodevening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hi what's up?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'what', \"'s\", 'up', '?']</td>\n",
       "      <td>['hi', 'what', \"'s\", 'up', '?']</td>\n",
       "      <td>['hi', \"what's\", 'up?']</td>\n",
       "      <td>['hi', 'whats', 'up']</td>\n",
       "      <td>hiwhatsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hi how  are you</td>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>['hi', 'how', 'are', 'you']</td>\n",
       "      <td>hihowareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how's the weather</td>\n",
       "      <td>weather</td>\n",
       "      <td>['how', \"'s\", 'the', 'weather']</td>\n",
       "      <td>['how', \"'s\", 'the', 'weather']</td>\n",
       "      <td>[\"how's\", 'the', 'weather']</td>\n",
       "      <td>['hows', 'the', 'weather']</td>\n",
       "      <td>howstheweather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>what's the weather like</td>\n",
       "      <td>get_weather</td>\n",
       "      <td>['what', \"'s\", 'the', 'weather', 'like']</td>\n",
       "      <td>['what', \"'s\", 'the', 'weather', 'like']</td>\n",
       "      <td>[\"what's\", 'the', 'weather', 'like']</td>\n",
       "      <td>['whats', 'the', 'weather', 'like']</td>\n",
       "      <td>whatstheweatherlike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what's the temperature</td>\n",
       "      <td>get_weather</td>\n",
       "      <td>['what', \"'s\", 'the', 'temperature']</td>\n",
       "      <td>['what', \"'s\", 'the', 'temperatur']</td>\n",
       "      <td>[\"what's\", 'the', 'temperature']</td>\n",
       "      <td>['whats', 'the', 'temperature']</td>\n",
       "      <td>whatsthetemperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>temperature</td>\n",
       "      <td>get_weather</td>\n",
       "      <td>['temperature']</td>\n",
       "      <td>['temperatur']</td>\n",
       "      <td>['temperature']</td>\n",
       "      <td>['temperature']</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>humidity</td>\n",
       "      <td>get_weather</td>\n",
       "      <td>['humidity']</td>\n",
       "      <td>['humid']</td>\n",
       "      <td>['humidity']</td>\n",
       "      <td>['humidity']</td>\n",
       "      <td>humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>what is the humidity</td>\n",
       "      <td>get_weather</td>\n",
       "      <td>['what', 'is', 'the', 'humidity']</td>\n",
       "      <td>['what', 'is', 'the', 'humid']</td>\n",
       "      <td>['what', 'is', 'the', 'humidity']</td>\n",
       "      <td>['what', 'is', 'the', 'humidity']</td>\n",
       "      <td>whatisthehumidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>how hot is it in mumbai?</td>\n",
       "      <td>get_weather</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai?']</td>\n",
       "      <td>['how', 'hot', 'is', 'it', 'in', 'mumbai']</td>\n",
       "      <td>howhotisitinmumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text       intent  \\\n",
       "0                   hi jarvis     greeting   \n",
       "1           hello goodmorning     greeting   \n",
       "2   hello jarvis how are you?     greeting   \n",
       "3                good morning     greeting   \n",
       "4              good afternoon     greeting   \n",
       "5                how are you?     greeting   \n",
       "6                       hello     greeting   \n",
       "7                  what's up?     greeting   \n",
       "8          hello good evening     greeting   \n",
       "9              hi goodmorning     greeting   \n",
       "10             hi goodevening     greeting   \n",
       "11              hi what's up?     greeting   \n",
       "12            hi how  are you     greeting   \n",
       "13          how's the weather      weather   \n",
       "14    what's the weather like  get_weather   \n",
       "15     what's the temperature  get_weather   \n",
       "16                temperature  get_weather   \n",
       "17                   humidity  get_weather   \n",
       "18       what is the humidity  get_weather   \n",
       "19   how hot is it in mumbai?  get_weather   \n",
       "\n",
       "                                     tokenized_text  \\\n",
       "0                                  ['hi', 'jarvis']   \n",
       "1                          ['hello', 'goodmorning']   \n",
       "2     ['hello', 'jarvis', 'how', 'are', 'you', '?']   \n",
       "3                               ['good', 'morning']   \n",
       "4                             ['good', 'afternoon']   \n",
       "5                        ['how', 'are', 'you', '?']   \n",
       "6                                         ['hello']   \n",
       "7                         ['what', \"'s\", 'up', '?']   \n",
       "8                      ['hello', 'good', 'evening']   \n",
       "9                             ['hi', 'goodmorning']   \n",
       "10                            ['hi', 'goodevening']   \n",
       "11                  ['hi', 'what', \"'s\", 'up', '?']   \n",
       "12                      ['hi', 'how', 'are', 'you']   \n",
       "13                  ['how', \"'s\", 'the', 'weather']   \n",
       "14         ['what', \"'s\", 'the', 'weather', 'like']   \n",
       "15             ['what', \"'s\", 'the', 'temperature']   \n",
       "16                                  ['temperature']   \n",
       "17                                     ['humidity']   \n",
       "18                ['what', 'is', 'the', 'humidity']   \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']   \n",
       "\n",
       "                                       stemmed_text  \\\n",
       "0                                   ['hi', 'jarvi']   \n",
       "1                             ['hello', 'goodmorn']   \n",
       "2      ['hello', 'jarvi', 'how', 'are', 'you', '?']   \n",
       "3                                  ['good', 'morn']   \n",
       "4                             ['good', 'afternoon']   \n",
       "5                        ['how', 'are', 'you', '?']   \n",
       "6                                         ['hello']   \n",
       "7                         ['what', \"'s\", 'up', '?']   \n",
       "8                         ['hello', 'good', 'even']   \n",
       "9                                ['hi', 'goodmorn']   \n",
       "10                               ['hi', 'goodeven']   \n",
       "11                  ['hi', 'what', \"'s\", 'up', '?']   \n",
       "12                      ['hi', 'how', 'are', 'you']   \n",
       "13                  ['how', \"'s\", 'the', 'weather']   \n",
       "14         ['what', \"'s\", 'the', 'weather', 'like']   \n",
       "15              ['what', \"'s\", 'the', 'temperatur']   \n",
       "16                                   ['temperatur']   \n",
       "17                                        ['humid']   \n",
       "18                   ['what', 'is', 'the', 'humid']   \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai', '?']   \n",
       "\n",
       "                                lemmatized_text  \\\n",
       "0                              ['hi', 'jarvis']   \n",
       "1                      ['hello', 'goodmorning']   \n",
       "2     ['hello', 'jarvis', 'how', 'are', 'you?']   \n",
       "3                           ['good', 'morning']   \n",
       "4                         ['good', 'afternoon']   \n",
       "5                        ['how', 'are', 'you?']   \n",
       "6                                     ['hello']   \n",
       "7                             [\"what's\", 'up?']   \n",
       "8                  ['hello', 'good', 'evening']   \n",
       "9                         ['hi', 'goodmorning']   \n",
       "10                        ['hi', 'goodevening']   \n",
       "11                      ['hi', \"what's\", 'up?']   \n",
       "12                  ['hi', 'how', 'are', 'you']   \n",
       "13                  [\"how's\", 'the', 'weather']   \n",
       "14         [\"what's\", 'the', 'weather', 'like']   \n",
       "15             [\"what's\", 'the', 'temperature']   \n",
       "16                              ['temperature']   \n",
       "17                                 ['humidity']   \n",
       "18            ['what', 'is', 'the', 'humidity']   \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai?']   \n",
       "\n",
       "                                  cleaned_text           joined_text  \n",
       "0                             ['hi', 'jarvis']              hijarvis  \n",
       "1                     ['hello', 'goodmorning']      hellogoodmorning  \n",
       "2     ['hello', 'jarvis', 'how', 'are', 'you']  hellojarvishowareyou  \n",
       "3                          ['good', 'morning']           goodmorning  \n",
       "4                        ['good', 'afternoon']         goodafternoon  \n",
       "5                        ['how', 'are', 'you']             howareyou  \n",
       "6                                    ['hello']                 hello  \n",
       "7                              ['whats', 'up']               whatsup  \n",
       "8                 ['hello', 'good', 'evening']      hellogoodevening  \n",
       "9                        ['hi', 'goodmorning']         higoodmorning  \n",
       "10                       ['hi', 'goodevening']         higoodevening  \n",
       "11                       ['hi', 'whats', 'up']             hiwhatsup  \n",
       "12                 ['hi', 'how', 'are', 'you']           hihowareyou  \n",
       "13                  ['hows', 'the', 'weather']        howstheweather  \n",
       "14         ['whats', 'the', 'weather', 'like']   whatstheweatherlike  \n",
       "15             ['whats', 'the', 'temperature']   whatsthetemperature  \n",
       "16                             ['temperature']           temperature  \n",
       "17                                ['humidity']              humidity  \n",
       "18           ['what', 'is', 'the', 'humidity']     whatisthehumidity  \n",
       "19  ['how', 'hot', 'is', 'it', 'in', 'mumbai']    howhotisitinmumbai  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85de936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Packages for Classification in Navie-Bayes\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer        #Used For Converting text into Numerical(Binary Data)\n",
    "from sklearn.model_selection import train_test_split               #Used for splitting dataset for Training and testing the performance\n",
    "from sklearn.naive_bayes     import MultinomialNB                  #Used for text based Classification & identify the intent\n",
    "from sklearn.metrics   import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c78634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hi', 'jarvi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'goodmorn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'jarvi', 'how', 'are', 'you', '?']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'morn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['good', 'afternoon']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>get_news</td>\n",
       "      <td>['tell', 'me', 'news', 'about', 'india', 'grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>leaving</td>\n",
       "      <td>['goodby', 'will', 'see', 'you', 'soon']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hey', 'how', 'are', 'you', '?']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hey', ',', 'how', 'are', 'you', 'do', 'today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hey', 'jarvi']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       intent                                       stemmed_text\n",
       "0    greeting                                    ['hi', 'jarvi']\n",
       "1    greeting                              ['hello', 'goodmorn']\n",
       "2    greeting       ['hello', 'jarvi', 'how', 'are', 'you', '?']\n",
       "3    greeting                                   ['good', 'morn']\n",
       "4    greeting                              ['good', 'afternoon']\n",
       "..        ...                                                ...\n",
       "184  get_news  ['tell', 'me', 'news', 'about', 'india', 'grow...\n",
       "185   leaving           ['goodby', 'will', 'see', 'you', 'soon']\n",
       "186  greeting                  ['hey', 'how', 'are', 'you', '?']\n",
       "187  greeting  ['hey', ',', 'how', 'are', 'you', 'do', 'today...\n",
       "188  greeting                                   ['hey', 'jarvi']\n",
       "\n",
       "[189 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a DataFrame\n",
    "df=pd.DataFrame(data)\n",
    "df[['intent','stemmed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b08842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868421052631579\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      get_news       1.00      1.00      1.00         2\n",
      "   get_weather       0.80      1.00      0.89        12\n",
      "      greeting       1.00      1.00      1.00         3\n",
      "          joke       1.00      1.00      1.00         3\n",
      "       leaving       1.00      1.00      1.00         1\n",
      "search _google       0.00      0.00      0.00         1\n",
      " search google       0.00      0.00      0.00         1\n",
      " search_google       1.00      0.86      0.92         7\n",
      "search_google        0.00      0.00      0.00         1\n",
      "search_youtube       0.60      1.00      0.75         3\n",
      "         timer       1.00      0.75      0.86         4\n",
      "\n",
      "      accuracy                           0.87        38\n",
      "     macro avg       0.67      0.69      0.67        38\n",
      "  weighted avg       0.83      0.87      0.84        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDESH VICHARE\\Downloads\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SIDDESH VICHARE\\Downloads\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SIDDESH VICHARE\\Downloads\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Spliting the data into training & Testing Sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['stemmed_text'],df['intent'],test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using CountVectorizer (you can also use TfidfVectorizer)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create and train the Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d303c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using CountVectorizer (you can also use TfidfVectorizer)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)       #Convert X_train into Numerical by fiting & transform\n",
    "X_test_vectorized = vectorizer.transform(X_test)             #Convert X_test into Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e7dbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "#Training the X_train(numerical) &  y_train(intent) data with MultiNomial\n",
    "nb_classifier.fit(X_train_vectorized, y_train)                        \n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb_classifier.predict(X_test_vectorized)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066688ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Classifier\n",
    "accuracy= accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909bbcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d7f6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "import re\n",
    "import webbrowser\n",
    "\n",
    "# Function to preprocess text of the user_input\n",
    "def preprocess_text(text):\n",
    "    #Here we put all the features to remove the meaningless text and lower-casing the input of user_input\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Create a pipeline with vectorizer and classifier which we re-use the model features in predicting the intent\n",
    "model_pipeline = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Chossing column to make the model to predict intent based on user inout \n",
    "X = df['cleaned_text']\n",
    "y = df['intent']\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "model_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d006caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import datetime\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "# speak('Hello, how may I help you')\n",
    "\n",
    "#Take Command and Converting into text from audio\n",
    "def takeCommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening.....\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        print(\"Recognizing....\")\n",
    "        query = r.recognize_google(audio, language='en-in')\n",
    "        print(f\"user said:{query}\\n\")\n",
    "        speak(query)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        print(\"say that again please......\")\n",
    "        speak(\"say that again sir.....\")\n",
    "        return \"None\"\n",
    "    return query\n",
    "speak('Hello, How can I help you')\n",
    "# takeCommand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff68bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text: open youtube\n",
      "Predicted Intent: search_youtube\n",
      "Listening.....\n",
      "Recognizing....\n",
      "user said:Tendulkar\n",
      "\n",
      "Enter your text: open yotuube\n",
      "Predicted Intent: search_youtube\n",
      "Listening.....\n",
      "Recognizing....\n",
      "user said:film songs\n",
      "\n",
      "Enter your text: open youtube\n",
      "Predicted Intent: search_youtube\n",
      "Listening.....\n",
      "Recognizing....\n",
      "user said:Malyalam songs\n",
      "\n",
      "Enter your text: news for today?\n",
      "Predicted Intent: get_news\n",
      "1. World's Most Powerful Passports: 6 Countries In Top Spot, India Ranks... - NDTV\n",
      "2. HIGHLIGHTS | IND Vs AFG, 1st T20I Full Scorecard: India Win By 6 Wickets, Take 1-0 Lead - Zee News\n",
      "3. Atal Setu inauguration: 10 interesting things to know about India's longest sea bridge | Mint - Mint\n",
      "\n",
      "Enter your text: hi\n",
      "Predicted Intent: greeting\n",
      "Enter your text: what is the weather in mumbai?\n",
      "Predicted Intent: get_weather\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Assume you have the preprocess_text function and model_pipeline variable defined somewhere in your code.\n",
    "\n",
    "def predict_intent(query):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess_text(query)\n",
    "    \n",
    "    # Use the trained pipeline to predict intent\n",
    "    predicted_intent = model_pipeline.predict([preprocessed_text])[0]   \n",
    "    return predicted_intent\n",
    "\n",
    "# function to get news based on user query\n",
    "def get_news(query):\n",
    "    try:\n",
    "        url = \"http://newsapi.org/v2/top-headlines?country=in&apiKey=3196e5c94880464fbb4f815b17d7c345\"\n",
    "        news_response = requests.get(url)\n",
    "        news_response.raise_for_status()  j\n",
    "\n",
    "        news = json.loads(news_response.text)\n",
    "        articles = news.get(\"articles\", [])\n",
    "\n",
    "        if not articles:\n",
    "            print(\"No articles found.\")\n",
    "            speak(\"Sorry, no articles found.\")\n",
    "            return \"No articles found.\"\n",
    "\n",
    "        headlines = \"\"\n",
    "        for id, article in enumerate(articles[:3], start=1):\n",
    "            title = article.get('title', '')\n",
    "            headlines += f\"{id}. {title}\\n\"\n",
    "        print(headlines)\n",
    "        speak(headlines)\n",
    "        return \"News fetching complete\"\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "        speak(f\"Sorry, there was an error fetching the news. Error: {e}\")\n",
    "        return f\"Error fetching news: {e}\"\n",
    "\n",
    "def get_weather(query):\n",
    "    api_key = 'f03be60b0a6b9e0be78f8d9866f0b663'\n",
    "    country = query.split()\n",
    "\n",
    "    # Check if there is at least one word in the input\n",
    "    if len(country) >= 5:  # Change to 5 to get the correct index for 'in'\n",
    "        country_name = country[5]\n",
    "    else:\n",
    "        print(\"Error: Please enter a valid query with at least two words.\")\n",
    "        return \"Error: Please enter a valid query with at least two words.\"\n",
    "\n",
    "    try:\n",
    "        url = f\"https://api.openweathermap.org/data/2.5/weather?q={country_name}&appid={api_key}\"\n",
    "        weather_response = requests.get(url)\n",
    "        weather_response.raise_for_status()\n",
    "        weather = json.loads(weather_response.text)\n",
    "\n",
    "        # Extracting weather information\n",
    "        description = weather['weather'][0]['description']\n",
    "        temperature = weather['main']['temp']\n",
    "        humidity = weather['main']['humidity']\n",
    "\n",
    "        response = f\"The current weather in {country_name} is {description.lower()} with a temperature of {temperature}°C and humidity of {humidity}%.\"\n",
    "        return response\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching weather: {e}\")\n",
    "        return \"Sorry, there was an error while fetching the weather.\"\n",
    "\n",
    "# function to search Google based on user query\n",
    "def search_google(query):\n",
    "    speak('What would you like to search on Google?')\n",
    "    search_query = takeCommand()\n",
    "    \n",
    "    if search_query:\n",
    "        speak(f'Searching for {search_query} on Google')\n",
    "        search_url = f'https://www.google.com/search?q={search_query}'\n",
    "        webbrowser.open(search_url)\n",
    "    else:\n",
    "        speak('No search query provided. Please try again.')\n",
    "        \n",
    "\n",
    "def search_youtube(query):\n",
    "    speak('What would you like to search on youtube')\n",
    "    search_query=takeCommand()\n",
    "    \n",
    "    if search_query:\n",
    "        speak(f'Searching for {search_query} on youtube')\n",
    "        search_url=f\"https://www.youtube.com/search?q={search_query}\"\n",
    "        webbrowser.open(search_url)\n",
    "    else:\n",
    "        speak('No search query provided. Please try again.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        # Get user command\n",
    "        query = input('Enter your text: ')\n",
    "\n",
    "        # Predict user intent\n",
    "        query = predict_intent(query)\n",
    "        print(f'Predicted Intent: {query}')\n",
    "\n",
    "        # Perform tasks based on the recognized intent\n",
    "        if 'search_google' in query:\n",
    "            search_google(query)\n",
    "        elif 'get_news' in query:\n",
    "            speak('News for Today')\n",
    "            get_news(query)\n",
    "        elif 'what is the weather in' in query:\n",
    "            weather_info = get_weather(query)\n",
    "            print(weather_info)\n",
    "            speak(weather_info)\n",
    "        elif 'greeting' in query:\n",
    "            speak('Hello how may I help you')\n",
    "        elif 'search_youtube' in query:\n",
    "            search_youtube(query)\n",
    "        elif 'joke' in query:\n",
    "            speak('You have to fetched API related to what jokes you like to hear')\n",
    "        \n",
    "        else:\n",
    "            print('Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20735e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain how the Tf-idf convert text into vectorizer(binary-form) which make model to understand \n",
    "\n",
    "|         | data | science | is | interesting | learning | essential | analysis | key | aspect |\n",
    "|---------|------|---------|----|-------------|----------|-----------|----------|-----|--------|\n",
    "| Doc 1   | 0.45 | 0.45    | 0.6| 0.79        | 0        | 0         | 0        | 0   | 0      |\n",
    "| Doc 2   | 0.45 | 0.45    | 0.6| 0          | 0.79     | 0.79      | 0        | 0   | 0      |\n",
    "| Doc 3   | 0.66 | 0.66    | 0  | 0          | 0        | 0         | 0.66     | 0.66| 0.66   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40771d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
